{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b569d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--infile\", \"-i\", type=str, help=\"CSV for dataset to expand\",\n",
    "#                     required=True)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "csvs=[\"twitter_topic_0.csv\",\"twitter_topic_1.csv\",\"twitter_topic_2.csv\",\"twitter_topic_3.csv\"]\n",
    "for csv in csvs:    \n",
    "    for topic in [\"lockdowns\", \"masking and distancing\", \"vaccination\",\"missing\"]:\n",
    "        df = pd.read_csv(csv)\n",
    "        cols = df.columns\n",
    "        for col in cols:\n",
    "            if \"annotation\" in col:\n",
    "                df[col] = (df[col].notna() & df[col].str.contains(topic))\n",
    "        new_fn = re.sub(r\"\\.csv$\", f\"_{topic.replace(' ', '_')}.csv\", csv)\n",
    "        df.to_csv(new_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76f27d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "twitter topic - 0 file label lockdowns : {'an1': 0.15310922941528948, 'an2': 0.20788424756793666, 'an3': 0.1699956795349352, 'an4': 0.20986808782839614}\n",
      "\n",
      "\n",
      "after delete minimum annotators {'an2': 0.20788424756793666, 'an4': 0.20986808782839614}\n",
      "\n",
      "\n",
      "----------------------------End of file 0 ------------------------------------\n",
      "\n",
      "twitter topic - 0 file label masking_and_distancing : {'an1': 0.5110966318263074, 'an2': 0.7704815888817947, 'an3': 0.7327868362752801, 'an4': 0.7630634070755388}\n",
      "\n",
      "\n",
      "after delete minimum annotators {'an1': 0.5110966318263074, 'an2': 0.7704815888817947, 'an3': 0.7327868362752801, 'an4': 0.7630634070755388}\n",
      "\n",
      "\n",
      "----------------------------End of file 0 ------------------------------------\n",
      "\n",
      "twitter topic - 0 file label vaccination : {'an1': 0.673287439979103, 'an2': 0.7621309462828351, 'an3': 0.6241408556645266, 'an4': 0.7095627314652487}\n",
      "\n",
      "\n",
      "after delete minimum annotators {'an1': 0.673287439979103, 'an2': 0.7621309462828351, 'an3': 0.6241408556645266, 'an4': 0.7095627314652487}\n",
      "\n",
      "\n",
      "----------------------------End of file 0 ------------------------------------\n",
      "\n",
      "twitter topic - 1 file label lockdowns : {'an1': 0.38374396729420157, 'an2': 0.2475066127986606, 'an3': 0.3466783318742191, 'an4': 0.3615994589823533}\n",
      "\n",
      "\n",
      "after delete minimum annotators {'an1': 0.38374396729420157, 'an2': 0.2475066127986606, 'an3': 0.3466783318742191, 'an4': 0.3615994589823533}\n",
      "\n",
      "\n",
      "----------------------------End of file 1 ------------------------------------\n",
      "\n",
      "twitter topic - 1 file label masking_and_distancing : {'an1': 0.5547693664516317, 'an2': 0.6992497233396247, 'an3': 0.6807204926375218, 'an4': 0.7045924598892853}\n",
      "\n",
      "\n",
      "after delete minimum annotators {'an1': 0.5547693664516317, 'an2': 0.6992497233396247, 'an3': 0.6807204926375218, 'an4': 0.7045924598892853}\n",
      "\n",
      "\n",
      "----------------------------End of file 1 ------------------------------------\n",
      "\n",
      "twitter topic - 1 file label vaccination : {'an1': 0.6557455942279518, 'an2': 0.3626159972414958, 'an3': 0.6134981271639437, 'an4': 0.6083138882680158}\n",
      "\n",
      "\n",
      "after delete minimum annotators {'an1': 0.6557455942279518, 'an2': 0.3626159972414958, 'an3': 0.6134981271639437, 'an4': 0.6083138882680158}\n",
      "\n",
      "\n",
      "----------------------------End of file 1 ------------------------------------\n",
      "\n",
      "twitter topic - 2 file label lockdowns : {'an1': 0.1163835813527575, 'an2': 0.30077990922116665, 'an3': 0.19539052471284699, 'an4': 0.30290799595403145}\n",
      "\n",
      "\n",
      "after delete minimum annotators {'an2': 0.30077990922116665, 'an4': 0.30290799595403145}\n",
      "\n",
      "\n",
      "----------------------------End of file 2 ------------------------------------\n",
      "\n",
      "twitter topic - 2 file label masking_and_distancing : {'an1': 0.6346300788322754, 'an2': 0.6029432092245662, 'an3': 0.5641640469267309, 'an4': 0.6629464534041484}\n",
      "\n",
      "\n",
      "after delete minimum annotators {'an1': 0.6346300788322754, 'an2': 0.6029432092245662, 'an3': 0.5641640469267309, 'an4': 0.6629464534041484}\n",
      "\n",
      "\n",
      "----------------------------End of file 2 ------------------------------------\n",
      "\n",
      "twitter topic - 2 file label vaccination : {'an1': 0.6901550441139593, 'an2': 0.6946177360097107, 'an3': 0.5853754265879894, 'an4': 0.7371881632778615}\n",
      "\n",
      "\n",
      "after delete minimum annotators {'an1': 0.6901550441139593, 'an2': 0.6946177360097107, 'an3': 0.5853754265879894, 'an4': 0.7371881632778615}\n",
      "\n",
      "\n",
      "----------------------------End of file 2 ------------------------------------\n",
      "\n",
      "twitter topic - 3 file label lockdowns : {'an1': 0.32835570175628914, 'an2': 0.21786806677463708, 'an3': 0.19204609283718876, 'an4': 0.2611111700445586}\n",
      "\n",
      "\n",
      "after delete minimum annotators {'an1': 0.32835570175628914, 'an2': 0.21786806677463708, 'an4': 0.2611111700445586}\n",
      "\n",
      "\n",
      "----------------------------End of file 3 ------------------------------------\n",
      "\n",
      "twitter topic - 3 file label masking_and_distancing : {'an1': 0.8319435933703723, 'an2': 0.8032421828800219, 'an3': 0.8556110752019936, 'an4': 0.8140977640978617}\n",
      "\n",
      "\n",
      "after delete minimum annotators {'an1': 0.8319435933703723, 'an2': 0.8032421828800219, 'an3': 0.8556110752019936, 'an4': 0.8140977640978617}\n",
      "\n",
      "\n",
      "----------------------------End of file 3 ------------------------------------\n",
      "\n",
      "twitter topic - 3 file label vaccination : {'an1': 0.6676275621130413, 'an2': 0.657906452588274, 'an3': 0.6207114581266412, 'an4': 0.6359096142185358}\n",
      "\n",
      "\n",
      "after delete minimum annotators {'an1': 0.6676275621130413, 'an2': 0.657906452588274, 'an3': 0.6207114581266412, 'an4': 0.6359096142185358}\n",
      "\n",
      "\n",
      "----------------------------End of file 3 ------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# PART 1\n",
    "# PART 1\n",
    "# PART 1\n",
    "\n",
    "# 1,2 done\n",
    "# 3. renamed all missing rows with \"missing\" & loading csv file from dataframe\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import csv\n",
    "\n",
    "# list of labels created\n",
    "labels = [\"lockdowns\", \"masking_and_distancing\", \"vaccination\"]\n",
    "\n",
    "# insitialising final dictionary output \n",
    "final_labels = {\"lockdowns\": {\"text\":\"label\"},\"masking_and_distancing\": {\"text\":\"label\"},\"vaccination\": {\"text\":\"label\"}}\n",
    "\n",
    "# inistilaizong final dic object\n",
    "accum_labels={\"text\":\"label\"}\n",
    "\n",
    "\n",
    "# iterrating given 4 files of twitter_topic\n",
    "for i in range(0,4):\n",
    "    for label in labels:\n",
    "        # reading csv\n",
    "        df = pd.read_csv('twitter_topic_'+str(i)+'_' + label + '.csv', skiprows=0)\n",
    "        df.columns = [\"text\", \"an1\", \"an2\", \"an3\", \"an4\"]\n",
    "        # using sklearn cohen_kappa_score\n",
    "        kappa_an_1_2 = cohen_kappa_score(df[\"an1\"], df[\"an2\"])\n",
    "        kappa_an_1_3 = cohen_kappa_score(df[\"an1\"], df[\"an3\"])\n",
    "        kappa_an_1_4 = cohen_kappa_score(df[\"an1\"], df[\"an4\"])\n",
    "        kappa_an_2_3 = cohen_kappa_score(df[\"an2\"], df[\"an3\"])\n",
    "        kappa_an_2_4 = cohen_kappa_score(df[\"an2\"], df[\"an4\"])\n",
    "        kappa_an_3_4 = cohen_kappa_score(df[\"an3\"], df[\"an4\"])\n",
    "\n",
    "        annotators = {}\n",
    "        # taking mean of the kappa score\n",
    "        annotators[\"an1\"] = (kappa_an_1_2 + kappa_an_1_3 + kappa_an_1_4) / 3\n",
    "        annotators[\"an2\"] = (kappa_an_1_2 + kappa_an_2_3 + kappa_an_2_4) / 3\n",
    "        annotators[\"an3\"] = (kappa_an_1_3 + kappa_an_2_3 + kappa_an_3_4) / 3\n",
    "        annotators[\"an4\"] = (kappa_an_1_4 + kappa_an_2_4 + kappa_an_3_4) / 3\n",
    "        \n",
    "# PART TWO\n",
    "# PART TWO\n",
    "# PART TWO\n",
    "\n",
    "        \n",
    "        print(\"\\ntwitter topic -\",i,\"file label\", label, \":\" ,str(annotators))\n",
    "        \n",
    "        # 1. eliminate any labels for annotators whose average kappa score is less than 0.2 (unreliable annotators)\n",
    "        delItems = []\n",
    "        for key, value in annotators.items():\n",
    "            if value<0.2:\n",
    "                delItems.append(key)\n",
    "        for j in delItems:\n",
    "            del annotators[j]\n",
    "            df = df.drop(j, 1)\n",
    "        print(\"\\n\")\n",
    "        print(\"after delete minimum annotators\", annotators)\n",
    "        print(\"\\n\")\n",
    "        # logic to generate the key value pairs for csv\n",
    "        for index, row in df.iterrows():\n",
    "            count = Counter(row[1:]).most_common(1)\n",
    "            if count == 1:\n",
    "                # 3. If there are ties (the same number of annotators for different labels), use the label with higher-reliability annotators (higher kappa scores on average)\n",
    "                v = row[max(annotators, key=annotators.get)]\n",
    "                try:\n",
    "                    values = accum_labels[row[0]]\n",
    "                except KeyError:\n",
    "                    accum_labels[row[0]] = []\n",
    "                accum_labels[row[0]].append(label)\n",
    "                final_labels[v][row[0]]= v\n",
    "            else:\n",
    "                # 2. assign the final label to each text as the most frequent label among the remainiing annotators\n",
    "                try:\n",
    "                    values = accum_labels[row[0]]\n",
    "                except KeyError:\n",
    "                    accum_labels[row[0]] = []\n",
    "                if count[0][0] is True:\n",
    "                    accum_labels[row[0]].append(label)\n",
    "                    final_labels[label][row[0]]= count[0][0]\n",
    "                else:\n",
    "                    final_labels[label][row[0]]= count[0][0]\n",
    "        print('----------------------------End of file',i,'------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a338817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all of the text/label pairs for the SECONDARY dataset into a single CSV file, with the columns \"text\" and \"label\"\n",
    "labels = [\"lockdowns\", \"masking_and_distancing\", \"vaccination\"]\n",
    "for label in labels:\n",
    "    with open('twitter_topic_'+label+'.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for row in final_labels[label].items():\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39834d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating overall file with key as text and values as list of annotations\n",
    "with open('twitter_final_label.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in accum_labels.items():\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
